{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sehui\\anaconda3\\envs\\BISPL\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from rdkit import Chem\n",
    "import pickle\n",
    "\n",
    "from calc_property import calculate_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, data_path, data_length=None, shuffle=False):\n",
    "        with open(data_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        self.data = [l.strip() for l in lines]\n",
    "\n",
    "        with open('./normalize.pkl', 'rb') as w:\n",
    "            norm = pickle.load(w)\n",
    "        self.property_mean, self.property_std = norm\n",
    "\n",
    "        if shuffle:\n",
    "            random.shuffle(self.data)\n",
    "        \n",
    "        ## Why need this line? ##\n",
    "        if data_length is not None:\n",
    "            self.data = self.data[data_length[0]: data_length[1]]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = 'Q' + self.data[idx]\n",
    "        properties = (calculate_property(smiles[1:])-self.property_std) / self.property_mean\n",
    "        \n",
    "        return smiles, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('QCN(c1ccccc1)c1ccccc1C(=O)NCC1(O)CCOCC1',\n",
       " tensor([  0.5682,   0.4030,   0.6777,   0.6901,   0.6560,   0.6904,   0.6890,\n",
       "           0.6158,   0.6544,   0.3731,   0.6623,  -1.0214,   0.5386,  -6.4296,\n",
       "           0.6370,   0.7405,   0.7696,   0.8429,   0.2686,   1.6701,   0.6852,\n",
       "           0.6222,   0.6510,   0.5670,   0.3475,   0.6824,   0.8768,   0.8768,\n",
       "          -0.1836,   2.4966,   0.1489,   0.7014,   0.6364,   0.2755,   0.4956,\n",
       "          -2.3909,   0.4995,   0.0625,   0.7835,  -1.1521,   0.3690,   0.4610,\n",
       "           0.6192,   0.3638, -29.1460,   0.2716,  -2.7021,   0.9223,   0.2647,\n",
       "           0.6883,   0.5710,   0.4035,   1.0784]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDataset = SMILESDataset(data_path='./data/pubchem-1m-simple.txt', data_length=None, shuffle=False)\n",
    "sample = sampleDataset.__getitem__(0)\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 2.0210e+00,  7.5875e+02,  1.7544e+01,  1.4052e+01,  1.4723e+01,\n",
      "         1.1664e+01,  8.1625e+00,  8.8090e+00,  6.2020e+00,  6.9684e+00,\n",
      "         4.2730e+00,  4.9467e+00,  2.9353e+00,  3.5438e+00,  3.5288e+02,\n",
      "         1.1951e+00,  1.9034e+00,  2.5342e+00,  4.1357e-01, -2.1272e+00,\n",
      "         2.4343e+01,  3.3127e+02,  1.7561e+01,  7.6679e+00,  4.3503e+00,\n",
      "         1.4605e+02,  1.1184e+01,  1.1184e+01,  1.9147e-01, -9.6040e-01,\n",
      "         2.6799e+00,  9.4141e+01,  3.5333e+02,  1.7290e+00,  5.1585e+00,\n",
      "         2.6400e-01,  5.4614e-01,  8.1014e-01,  1.1892e+00,  7.1781e-01,\n",
      "         1.9070e+00,  4.0690e+00,  1.3547e+00,  6.2828e+00,  4.5800e-03,\n",
      "         5.4205e+00,  2.0371e-01,  3.9774e-01,  6.0145e-01,  1.2960e+02,\n",
      "         2.7171e+00,  6.8247e+01,  6.1739e-01]), tensor([5.9750e-01, 4.0613e+02, 5.8108e+00, 4.7454e+00, 4.7843e+00, 4.0368e+00,\n",
      "        2.9280e+00, 3.1273e+00, 2.3723e+00, 3.8311e+00, 1.8252e+00, 9.7076e+00,\n",
      "        1.4360e+00, 2.5803e+01, 1.1541e+02, 2.3501e-01, 2.9517e-01, 3.4393e-01,\n",
      "        2.3890e-01, 1.1825e+00, 8.3198e+00, 1.1012e+02, 6.0206e+00, 3.3283e+00,\n",
      "        2.6729e+00, 4.8121e+01, 2.9003e+00, 2.9004e+00, 2.1729e-01, 1.5170e+00,\n",
      "        2.3267e+00, 3.2254e+01, 1.1555e+02, 1.5236e+00, 2.4436e+00, 6.3120e-01,\n",
      "        7.2720e-01, 9.4935e-01, 1.0682e+00, 8.2700e-01, 1.2962e+00, 2.1244e+00,\n",
      "        1.1611e+00, 2.7145e+00, 1.3349e-01, 3.5276e+00, 5.5045e-01, 6.3316e-01,\n",
      "        8.4078e-01, 4.2797e+01, 1.4486e+00, 3.4261e+01, 2.1272e-01]))\n"
     ]
    }
   ],
   "source": [
    "with open('./data/pubchem-1m-simple.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "with open('./normalize.pkl', 'rb') as w:\n",
    "    norm = pickle.load(w)\n",
    "    print(norm)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Custom Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file= \"./vocab_bpe_300.txt\" ,lowercase=False, do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>##c12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>##[Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>##c(C(=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>##[nH+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>##(CC(=O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0       [PAD]\n",
       "1       [UNK]\n",
       "2       [CLS]\n",
       "3       [SEP]\n",
       "4      [MASK]\n",
       "..        ...\n",
       "295     ##c12\n",
       "296     ##[Si\n",
       "297  ##c(C(=O\n",
       "298   ##[nH+]\n",
       "299  ##(CC(=O\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_fwf('./vocab_bpe_300.txt', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit import Chem\n",
    "# from transformers import BertTokenizer\n",
    "\n",
    "# from typing import List\n",
    "# import re\n",
    "\n",
    "# ## REGEX_PATTERN ##\n",
    "# SMI_REGEX_PATTERN =  r\"(\\%\\([0-9]{3}\\)|\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\||\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "\n",
    "# class RegexTokenizer:\n",
    "#     \"\"\"Run regex tokenization\"\"\"\n",
    "\n",
    "#     def __init__(self, regex_pattern: str=SMI_REGEX_PATTERN) -> None:\n",
    "#         \"\"\"Constructs a RegexTokenizer.\n",
    "#         Args:\n",
    "#             regex_pattern: regex pattern used for tokenization.\n",
    "#             suffix: optional suffix for the tokens. Defaults to \"\".\n",
    "#         \"\"\"\n",
    "#         self.regex_pattern = regex_pattern\n",
    "#         self.regex = re.compile(self.regex_pattern)\n",
    "\n",
    "#     def tokenize(self, text: str) -> List[str]:\n",
    "#         \"\"\"Regex tokenization.\n",
    "#         Args:\n",
    "#             text: text to tokenize.\n",
    "#         Returns:\n",
    "#             extracted tokens separated by spaces.\n",
    "#         \"\"\"\n",
    "#         tokens = [token for token in self.regex.findall(text)]\n",
    "#         return tokens\n",
    "    \n",
    "    \n",
    "# class SMILESTokenizer(BertTokenizer):\n",
    "#     def __init__(self, \n",
    "#         vocab_file: str,\n",
    "#         unk_token: str = \"[UNK]\",\n",
    "#         sep_token: str = \"[SEP]\",\n",
    "#         pad_token: str = \"[PAD]\",\n",
    "#         cls_token: str = \"[CLS]\",\n",
    "#         mask_token: str = \"[MASK]\",\n",
    "#         do_lower_case = False,\n",
    "#         **kwargs,\n",
    "#         ) -> None:\n",
    "        \n",
    "#         super().__init__(\n",
    "#             vocab_file=vocab_file,\n",
    "#             unk_token=unk_token,\n",
    "#             sep_token=sep_token,\n",
    "#             pad_token=pad_token,\n",
    "#             cls_token=cls_token,\n",
    "#             mask_token=mask_token,\n",
    "#             do_lower_case=do_lower_case,\n",
    "#             **kwargs,\n",
    "#         )\n",
    "        \n",
    "#         self.tokenizer = RegexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_config = {\n",
    "        'embed_dim': 256,#256\n",
    "        'property_width': 384, #???\n",
    "        'batch_size': 4,#64\n",
    "        'temp': 0.07,\n",
    "        'queue_size': 2048,#65536\n",
    "        'momentum': 0.995,\n",
    "        'alpha': 0.4,\n",
    "        'bert_config': './config_bert.json',    #config file for BERT model. The configuration for ViT can be manually changed in albef.py\n",
    "        'schedular': {'sched': 'cosine', 'lr': 1e-4, 'epochs': 30, 'min_lr': 1e-5,\n",
    "                      'decay_rate': 1, 'warmup_lr': 1e-5, 'warmup_epochs': 20, 'cooldown_epochs': 0},\n",
    "        'optimizer': {'opt': 'adamW', 'lr': 1e-4, 'weight_decay': 0.02}\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   5, 146,   8, 212, 112, 115,  98, 222, 114,  98,   3]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "sample_SMILES = sample[0]\n",
    "sample_prop = sample[1]\n",
    "\n",
    "SMILES_token = tokenizer(sample_SMILES)\n",
    "input_ids = torch.LongTensor([SMILES_token['input_ids']])\n",
    "print(input_ids)\n",
    "attention_mask = torch.Tensor([SMILES_token['attention_mask']])\n",
    "print(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbert import BertConfig, BertForMaskedLM\n",
    "\n",
    "smilesAndFusion_config = BertConfig.from_json_file('./config_bert_smiles_and_fusion_encoder.json')\n",
    "smilesEncoder = BertForMaskedLM(config = smilesAndFusion_config)\n",
    "\n",
    "property_config = BertConfig.from_json_file('./config_bert_property_encoder.json')\n",
    "propertyEncoder = BertForMaskedLM(config = property_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.2091,  0.7468,  0.5669,  ..., -0.3899, -0.4842, -0.5266],\n",
      "         [-0.9721,  0.7393,  0.7513,  ..., -0.7073, -0.1890, -0.3069],\n",
      "         [-0.8090,  0.7342,  0.8782,  ..., -0.9258,  0.0142, -0.1556],\n",
      "         ...,\n",
      "         [-0.9783,  0.7395,  0.7465,  ..., -0.6990, -0.1967, -0.3126],\n",
      "         [-1.0535,  0.7419,  0.6879,  ..., -0.5982, -0.2904, -0.3824],\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "propertyOriginal = torch.rand([1,53])\n",
    "embedProperty = nn.Linear(1, 384)(propertyOriginal.unsqueeze(2))\n",
    "#print(embedProperty)\n",
    "\n",
    "property_CLS = nn.Parameter(torch.zeros([1,1,384]))\n",
    "property_MASK = nn.Parameter(torch.zeros([1,1,384]))\n",
    "property_MASK = property_MASK.expand(propertyOriginal.size(0), propertyOriginal.size(1), -1)\n",
    "\n",
    "halfMask = torch.bernoulli(torch.ones_like(propertyOriginal)*0.5)\n",
    "halfMaskBatch = halfMask.unsqueeze(2).repeat(1,1,property_MASK.size(2))\n",
    "maskedProperty = embedProperty*halfMaskBatch + property_MASK*halfMaskBatch\n",
    "\n",
    "print((embedProperty*halfMaskBatch))\n",
    "#print(property_MASK*(1-halfMaskBatch))\n",
    "\n",
    "inputProperty = torch.cat([property_CLS.expand(propertyOriginal.size(0), -1,-1), maskedProperty], dim=1)\n",
    "\n",
    "#print(inputProperty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 54, 384])\n",
      "torch.Size([1, 12, 384])\n"
     ]
    }
   ],
   "source": [
    "encodedProp = propertyEncoder.bert(inputs_embeds=inputProperty, return_dict=True).last_hidden_state\n",
    "print(encodedProp.shape)\n",
    "encodedSmiles = smilesEncoder.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True, mode='text').last_hidden_state\n",
    "print(encodedSmiles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.1473e-02,  1.2620e+00, -2.4469e-01,  ...,  4.6948e-01,\n",
       "         -1.9055e+00,  4.4526e-02],\n",
       "        [-5.4801e-03, -8.3393e-01, -7.7849e-01,  ..., -8.4742e-01,\n",
       "         -3.9457e-01,  1.6535e+00],\n",
       "        [-1.1821e-02,  1.0043e-01,  8.3092e-01,  ..., -9.1041e-01,\n",
       "          9.8655e-01, -6.2190e-01],\n",
       "        ...,\n",
       "        [-6.8584e-03, -7.7725e-01, -4.7841e-01,  ...,  1.0659e+00,\n",
       "          7.5329e-01, -7.4068e-01],\n",
       "        [-1.5319e-03, -2.4126e-01,  1.1897e+00,  ..., -2.3796e-01,\n",
       "          5.4816e-03, -2.4479e+00],\n",
       "        [-1.7260e-02,  4.3282e-02,  9.1374e-02,  ...,  1.2826e-01,\n",
       "         -6.8140e-01,  1.1980e+00]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "propertyProj = nn.Linear(384, 384)\n",
    "\n",
    "propertyAtts = torch.ones(encodedProp.size()[:-1], dtype=torch.long).to(inputProperty.device)\n",
    "propertyFeat = F.normalize(propertyProj(encodedProp[:,0,:]), dim=-1)\n",
    "\n",
    "property_queue = torch.randn(384, 2048)\n",
    "property_queue.clone().detach()\n",
    "\n",
    "propertyFeatAll = torch.cat([propertyFeat.t(), property_queue.clone().detach()], dim=1)\n",
    "propertyFeatAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.1473e-02,  1.2620e+00, -2.4469e-01,  ...,  4.6948e-01,\n",
       "         -1.9055e+00,  4.4526e-02],\n",
       "        [-5.4801e-03, -8.3393e-01, -7.7849e-01,  ..., -8.4742e-01,\n",
       "         -3.9457e-01,  1.6535e+00],\n",
       "        [-1.1821e-02,  1.0043e-01,  8.3092e-01,  ..., -9.1041e-01,\n",
       "          9.8655e-01, -6.2190e-01],\n",
       "        ...,\n",
       "        [-6.8584e-03, -7.7725e-01, -4.7841e-01,  ...,  1.0659e+00,\n",
       "          7.5329e-01, -7.4068e-01],\n",
       "        [-1.5319e-03, -2.4126e-01,  1.1897e+00,  ..., -2.3796e-01,\n",
       "          5.4816e-03, -2.4479e+00],\n",
       "        [-1.7260e-02,  4.3282e-02,  9.1374e-02,  ...,  1.2826e-01,\n",
       "         -6.8140e-01,  1.1980e+00]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesProj = nn.Linear(384, 384)\n",
    "smilesFeat = F.normalize(smilesProj(encodedSmiles[:,0,:]), dim=-1)\n",
    "\n",
    "smiles_queue = torch.randn(384, 2048)\n",
    "smiles_queue.clone().detach()\n",
    "\n",
    "smilesFeatAll = torch.cat([smilesFeat.t(), smiles_queue.clone().detach()], dim=1)\n",
    "propertyFeatAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2049])\n",
      "torch.Size([1, 2049])\n"
     ]
    }
   ],
   "source": [
    "sim_p2s = (propertyFeat @ smilesFeatAll)\n",
    "sim_targets = torch.zeros(sim_p2s.size()).to(propertyOriginal.device)\n",
    "print(sim_targets.shape)\n",
    "\n",
    "sim_s2p = smilesFeat @ propertyFeatAll\n",
    "sim_targets_same = torch.zeros(sim_s2p.size()).to(propertyOriginal.device)\n",
    "print(sim_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputProperty_pos = smilesEncoder.bert(encoder_embeds = encodedProp,\n",
    "                               attention_mask = propertyAtts,\n",
    "                               encoder_hidden_states = encodedSmiles,\n",
    "                               encoder_attention_mask = attention_mask,\n",
    "                               return_dict = True,\n",
    "                               mode= 'fusion'\n",
    "                               ).last_hidden_state[:,0,:]\n",
    "outputSmiles_pos = smilesEncoder.bert(encoder_embeds = encodedSmiles,\n",
    "                             attention_mask = attention_mask,\n",
    "                             encoder_hidden_states = encodedProp,\n",
    "                             encoder_attention_mask = propertyAtts,\n",
    "                             return_dict = True,\n",
    "                             mode= 'fusion'\n",
    "                             ).last_hidden_state[:,0,:]\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384])\n",
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "print(outputProperty_pos.shape)\n",
    "print(outputSmiles_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "weights_p2s = F.softmax(sim_p2s[:,:batch_size], dim=1)\n",
    "weights_s2p = F.softmax(sim_s2p[:,:batch_size], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.5329e-01, -1.0953e-01,  2.2853e-04,  ...,  1.3656e+00,\n",
       "          -7.2193e-01,  1.2645e+00],\n",
       "         [ 1.2098e-01,  5.5696e-01,  1.8438e-01,  ..., -8.4229e-01,\n",
       "           1.8129e-01, -8.6456e-01],\n",
       "         [-9.9603e-01,  5.1829e-01,  1.2027e+00,  ..., -6.8868e-01,\n",
       "           3.8952e-01, -4.1334e-01],\n",
       "         ...,\n",
       "         [-1.0247e+00,  4.8322e-01,  1.1923e+00,  ..., -5.1068e-01,\n",
       "           6.9675e-01, -3.3327e-01],\n",
       "         [-1.3248e+00,  7.0152e-01,  1.1969e+00,  ..., -3.7592e-01,\n",
       "           3.0733e-01, -3.8839e-01],\n",
       "         [-8.4820e-01, -6.5878e-01,  1.9948e-01,  ...,  8.2771e-01,\n",
       "          -1.0954e+00,  1.7565e+00]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedProp_neg = []\n",
    "neg_idx = torch.multinomial(weights_p2s[0], 1).item()\n",
    "encodedProp_neg.append(encodedProp[neg_idx])\n",
    "encodedProp_neg = torch.stack(encodedProp_neg, dim=0)\n",
    "encodedProp_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7729, -0.5451, -0.9563,  ...,  0.7439, -0.0239,  0.0329],\n",
       "         [ 0.6894, -0.5174,  1.0443,  ..., -0.5177, -1.0379, -0.5036],\n",
       "         [ 1.0968, -0.5394,  0.2805,  ...,  0.6875, -1.1454,  0.2677],\n",
       "         ...,\n",
       "         [ 1.1775, -0.7769, -0.1076,  ...,  0.4221, -0.9266,  0.1148],\n",
       "         [-0.9466, -0.3234,  0.0563,  ..., -1.1961, -1.0710,  0.1078],\n",
       "         [ 1.6689,  0.2071, -0.7971,  ..., -0.6911, -0.8274, -0.3584]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedSmiles_neg = []\n",
    "smilesAtts_neg = []\n",
    "\n",
    "neg_idx = torch.multinomial(weights_s2p[0], 1).item()\n",
    "encodedSmiles_neg.append(encodedSmiles[neg_idx])\n",
    "smilesAtts_neg.append(attention_mask[neg_idx])\n",
    "encodedSmiles_neg = torch.stack(encodedSmiles_neg, dim=0)\n",
    "smilesAtts_neg = torch.stack(smilesAtts_neg, dim=0)\n",
    "\n",
    "encodedSmiles_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encProperty_all = torch.cat([encodedProp, encodedProp_neg], dim=0)\n",
    "propertyAtts_all = torch.cat([propertyAtts, propertyAtts], dim=0)\n",
    "\n",
    "encSmiles_all = torch.cat([encodedSmiles_neg, encodedSmiles], dim=0)\n",
    "smilesAtts_all = torch.cat([smilesAtts_neg, attention_mask], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputProperty_neg = smilesEncoder.bert(encoder_embeds = encProperty_all,\n",
    "                                    attention_mask = propertyAtts_all,\n",
    "                                    encoder_hidden_states = encSmiles_all,\n",
    "                                    encoder_attention_mask = smilesAtts_all,\n",
    "                                    return_dict = True,\n",
    "                                    mode = 'fusion'\n",
    "                                    ).last_hidden_state[:,0,:]\n",
    "#outputProperty_neg = outputProperty_neg\n",
    "outputSmiles_neg = smilesEncoder.bert(encoder_embeds = encSmiles_all,\n",
    "                                    attention_mask = smilesAtts_all,\n",
    "                                    encoder_hidden_states = encProperty_all,\n",
    "                                    encoder_attention_mask = propertyAtts_all,\n",
    "                                    return_dict = True,\n",
    "                                    mode = 'fusion'\n",
    "                                    ).last_hidden_state[:,0,:]\n",
    "#outputSmiles_neg = outputSmiles_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0697,  0.6968],\n",
       "        [-0.0017,  0.7012],\n",
       "        [-0.2312,  0.6549]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeds = torch.cat([outputProperty_pos, outputSmiles_pos], dim=-1)\n",
    "neg_embeds = torch.cat([outputProperty_neg, outputSmiles_neg], dim=-1)\n",
    "\n",
    "ps_embeddings = torch.cat([pos_embeds, neg_embeds], dim=0)\n",
    "ps_embeddings.shape\n",
    "ps_output = nn.Linear(768, 2)(ps_embeddings)\n",
    "ps_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psm_labels = torch.cat([torch.ones(1, dtype=torch.long), torch.zeros(2, dtype=torch.long)], dim=0).to(propertyOriginal.device)\n",
    "psm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9215, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_psm = F.cross_entropy(ps_output, psm_labels)\n",
    "loss_psm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         False,  True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bernoulli(torch.full(input_ids.shape, 0.8)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 300])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_m  = smilesEncoder(input_ids,\n",
    "                          attention_mask = attention_mask,\n",
    "                          encoder_hidden_states = encodedProp,\n",
    "                          encoder_attention_mask = propertyAtts,\n",
    "                          return_dict = True,\n",
    "                          is_decoder = True,\n",
    "                          return_logits = True \n",
    "                          )[:,:-1,:]\n",
    "\n",
    "logits_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 300])\n",
      "torch.Size([1, 300, 11])\n",
      "torch.Size([1, 11])\n",
      "tensor(5.8270, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "labels = input_ids.clone()[:,1:]\n",
    "per_logits_m = logits_m.permute((0,2,1))\n",
    "\n",
    "print(logits_m.shape)\n",
    "print(per_logits_m.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "loss_nwp = loss_fct(per_logits_m,labels)\n",
    "\n",
    "print(loss_nwp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0163, -0.0203, -0.0246,  ..., -0.0223, -0.0222, -0.0359],\n",
       "         [-0.0231, -0.0214, -0.0131,  ..., -0.0189, -0.0156, -0.0178],\n",
       "         [-0.0227, -0.0155, -0.0276,  ..., -0.0193, -0.0155, -0.0279],\n",
       "         ...,\n",
       "         [-0.0159, -0.0172, -0.0138,  ..., -0.0264, -0.0229, -0.0256],\n",
       "         [-0.0195, -0.0200, -0.0153,  ..., -0.0151, -0.0234, -0.0110],\n",
       "         [-0.0191, -0.0100, -0.0222,  ..., -0.0183, -0.0143, -0.0142]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(logits_m, dim=-1) * F.softmax(logits_m, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 300])\n"
     ]
    }
   ],
   "source": [
    "F.softmax(logits_m, dim=-1)\n",
    "print(F.softmax(logits_m, dim=-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(64.2319, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_labels = F.softmax(logits_m, dim=1)\n",
    "loss_distill = -torch.sum(F.log_softmax(logits_m, dim=1) * soft_labels, dim=-1)\n",
    "\n",
    "loss_distill = (loss_distill * (labels != 0)).mean()\n",
    "loss_distill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3304,  0.4590, -0.5967,  ...,  1.2816, -0.1227,  1.2848],\n",
       "         [-1.2938,  0.6364,  0.7300,  ..., -0.3683,  0.0276, -0.8365],\n",
       "         [-0.9701, -0.5149,  1.2391,  ..., -0.7945,  0.4855, -0.5426],\n",
       "         ...,\n",
       "         [-0.9369,  0.4499,  1.2872,  ..., -1.0597,  0.2443, -0.2044],\n",
       "         [-1.2789,  0.2818,  0.8195,  ..., -0.6183,  0.3485, -0.5829],\n",
       "         [ 0.2594, -1.0350, -0.4422,  ...,  1.0007, -0.1293, -0.8713]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = propertyOriginal.clone()\n",
    "\n",
    "encProperty_masked_m = propertyEncoder.bert(inputs_embeds = inputProperty,\n",
    "                                       return_dict = True,\n",
    "                                       is_decoder = True\n",
    "                                       ).last_hidden_state\n",
    "encProperty_masked_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 53, 384])\n"
     ]
    }
   ],
   "source": [
    "npp_output_m = smilesEncoder.bert(encoder_embeds = encProperty_masked_m,\n",
    "                                  attention_mask = propertyAtts,\n",
    "                                  encoder_hidden_states = encodedSmiles,\n",
    "                                  encoder_attention_mask = attention_mask,    \n",
    "                                  return_dict = True,\n",
    "                                  is_decoder = True,\n",
    "                                  mode = 'fusion').last_hidden_state[:,:-1,:]\n",
    "\n",
    "#npp_output_m\n",
    "print(npp_output_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_reg = nn.Sequential(nn.Linear(384, 384),\n",
    "                           nn.GELU(),\n",
    "                           nn.LayerNorm(384, property_config.layer_norm_eps),\n",
    "                           nn.Linear(384, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 53])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_m = target_reg(npp_output_m)\n",
    "pred_m.squeeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 53])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertyTargets = propertyOriginal.clone() \n",
    "propertyTargets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sehui\\anaconda3\\envs\\BISPL\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 53])) that is different to the input size (torch.Size([1, 53, 53])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7448, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_MSE = nn.MSELoss()\n",
    "loss_npp = loss_MSE(pred_m*halfMask, propertyTargets*halfMask)\n",
    "loss_npp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "         0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.]])\n",
      "tensor([[0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
      "         1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(halfMask)\n",
    "print(1-halfMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrain_SPMM debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_config = {\n",
    "        'embed_dim': 256,#256\n",
    "        'property_width': 384, #???\n",
    "        'batch_size': 4,#64\n",
    "        'temp': 0.07,\n",
    "        'queue_size': 2048,#65536\n",
    "        'momentum': 0.995,\n",
    "        'alpha': 0.4,\n",
    "        'bert_config': './config_bert.json',    #config file for BERT model. The configuration for ViT can be manually changed in albef.py\n",
    "        'schedular': {'sched': 'cosine', 'lr': 1e-4, 'epochs': 30, 'min_lr': 1e-5,\n",
    "                      'decay_rate': 1, 'warmup_lr': 1e-5, 'warmup_epochs': 20, 'cooldown_epochs': 0},\n",
    "        'optimizer': {'opt': 'adamW', 'lr': 1e-4, 'weight_decay': 0.02}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sehui\\anaconda3\\envs\\BISPL\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn \n",
    "from xbert import BertConfig, BertForMaskedLM\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from pretrain_SPMM import SPMM\n",
    "from transformers import BertTokenizer\n",
    "from dataset import SMILESDataset\n",
    "\n",
    "sampleDataset = SMILESDataset(data_path='./data/pubchem-1m-simple.txt', data_length=None, shuffle=False)\n",
    "sample = sampleDataset.__getitem__(0)\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file= \"./vocab_bpe_300.txt\" ,lowercase=False, do_basic_tokenize=False)\n",
    "sample_SMILES = sample[0]\n",
    "sample_prop = sample[1]\n",
    "\n",
    "SMILES_token = tokenizer(sample_SMILES)\n",
    "input_ids = torch.LongTensor([SMILES_token['input_ids']])\n",
    "attention_mask = torch.Tensor([SMILES_token['attention_mask']])\n",
    "\n",
    "propertyOriginal = sample_prop.unsqueeze(0)\n",
    "\n",
    "model = SPMM(config=pretrain_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BertForMaskedLM.forward() got an unexpected keyword argument 'return_dic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model(propertyOriginal, input_ids, attention_mask, alpha\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sehui\\anaconda3\\envs\\BISPL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sehui\\Desktop\\HongEun\\SPMM_Reproduction\\pretrain_SPMM.py:96\u001b[0m, in \u001b[0;36mSPMM.forward\u001b[1;34m(self, property, smilesIds, smilesAttentionMask, alpha)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     94\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_momentum_update()\n\u001b[1;32m---> 96\u001b[0m     encProperty_m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropertyEncoder_m(inputs_embeds\u001b[39m=\u001b[39;49minputProperty, return_dic\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[0;32m     97\u001b[0m     \u001b[39m#propertyAtts_m = torch.ones(encProperty_m.size()[:-1], dtype=torch.long).to(inputProperty.device)\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     propertyFeat_m \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnormalize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropertyProj_m(encProperty_m[:,\u001b[39m0\u001b[39m,:]), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sehui\\anaconda3\\envs\\BISPL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: BertForMaskedLM.forward() got an unexpected keyword argument 'return_dic'"
     ]
    }
   ],
   "source": [
    "model(propertyOriginal, input_ids, attention_mask, alpha=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BISPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01a600ee4c343e99426c2b6e5bbd26d22d733d8f4b38429737b3f68048676463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
