{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sehui\\anaconda3\\envs\\BISPL\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from rdkit import Chem\n",
    "import pickle\n",
    "\n",
    "from calc_property import calculate_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, data_path, data_length=None, shuffle=False):\n",
    "        with open(data_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        self.data = [l.strip() for l in lines]\n",
    "\n",
    "        with open('./normalize.pkl', 'rb') as w:\n",
    "            norm = pickle.load(w)\n",
    "        self.property_mean, self.property_std = norm\n",
    "\n",
    "        if shuffle:\n",
    "            random.shuffle(self.data)\n",
    "        \n",
    "        ## Why need this line? ##\n",
    "        if data_length is not None:\n",
    "            self.data = self.data[data_length[0]: data_length[1]]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = 'Q' + self.data[idx]\n",
    "        properties = (calculate_property(smiles[1:])-self.property_std) / self.property_mean\n",
    "        \n",
    "        return smiles, properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('QCN(c1ccccc1)c1ccccc1C(=O)NCC1(O)CCOCC1',\n",
       " tensor([  0.5682,   0.4030,   0.6777,   0.6901,   0.6560,   0.6904,   0.6890,\n",
       "           0.6158,   0.6544,   0.3731,   0.6623,  -1.0214,   0.5386,  -6.4296,\n",
       "           0.6370,   0.7405,   0.7696,   0.8429,   0.2686,   1.6701,   0.6852,\n",
       "           0.6222,   0.6510,   0.5670,   0.3475,   0.6824,   0.8768,   0.8768,\n",
       "          -0.1836,   2.4966,   0.1489,   0.7014,   0.6364,   0.2755,   0.4956,\n",
       "          -2.3909,   0.4995,   0.0625,   0.7835,  -1.1521,   0.3690,   0.4610,\n",
       "           0.6192,   0.3638, -29.1460,   0.2716,  -2.7021,   0.9223,   0.2647,\n",
       "           0.6883,   0.5710,   0.4035,   1.0784]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDataset = SMILESDataset(data_path='./data/pubchem-1m-simple.txt', data_length=None, shuffle=False)\n",
    "sample = sampleDataset.__getitem__(0)\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 2.0210e+00,  7.5875e+02,  1.7544e+01,  1.4052e+01,  1.4723e+01,\n",
      "         1.1664e+01,  8.1625e+00,  8.8090e+00,  6.2020e+00,  6.9684e+00,\n",
      "         4.2730e+00,  4.9467e+00,  2.9353e+00,  3.5438e+00,  3.5288e+02,\n",
      "         1.1951e+00,  1.9034e+00,  2.5342e+00,  4.1357e-01, -2.1272e+00,\n",
      "         2.4343e+01,  3.3127e+02,  1.7561e+01,  7.6679e+00,  4.3503e+00,\n",
      "         1.4605e+02,  1.1184e+01,  1.1184e+01,  1.9147e-01, -9.6040e-01,\n",
      "         2.6799e+00,  9.4141e+01,  3.5333e+02,  1.7290e+00,  5.1585e+00,\n",
      "         2.6400e-01,  5.4614e-01,  8.1014e-01,  1.1892e+00,  7.1781e-01,\n",
      "         1.9070e+00,  4.0690e+00,  1.3547e+00,  6.2828e+00,  4.5800e-03,\n",
      "         5.4205e+00,  2.0371e-01,  3.9774e-01,  6.0145e-01,  1.2960e+02,\n",
      "         2.7171e+00,  6.8247e+01,  6.1739e-01]), tensor([5.9750e-01, 4.0613e+02, 5.8108e+00, 4.7454e+00, 4.7843e+00, 4.0368e+00,\n",
      "        2.9280e+00, 3.1273e+00, 2.3723e+00, 3.8311e+00, 1.8252e+00, 9.7076e+00,\n",
      "        1.4360e+00, 2.5803e+01, 1.1541e+02, 2.3501e-01, 2.9517e-01, 3.4393e-01,\n",
      "        2.3890e-01, 1.1825e+00, 8.3198e+00, 1.1012e+02, 6.0206e+00, 3.3283e+00,\n",
      "        2.6729e+00, 4.8121e+01, 2.9003e+00, 2.9004e+00, 2.1729e-01, 1.5170e+00,\n",
      "        2.3267e+00, 3.2254e+01, 1.1555e+02, 1.5236e+00, 2.4436e+00, 6.3120e-01,\n",
      "        7.2720e-01, 9.4935e-01, 1.0682e+00, 8.2700e-01, 1.2962e+00, 2.1244e+00,\n",
      "        1.1611e+00, 2.7145e+00, 1.3349e-01, 3.5276e+00, 5.5045e-01, 6.3316e-01,\n",
      "        8.4078e-01, 4.2797e+01, 1.4486e+00, 3.4261e+01, 2.1272e-01]))\n"
     ]
    }
   ],
   "source": [
    "with open('./data/pubchem-1m-simple.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "with open('./normalize.pkl', 'rb') as w:\n",
    "    norm = pickle.load(w)\n",
    "    print(norm)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Custom Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file= \"./vocab_bpe_300.txt\" ,lowercase=False, do_basic_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[MASK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>##c12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>##[Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>##c(C(=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>##[nH+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>##(CC(=O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0       [PAD]\n",
       "1       [UNK]\n",
       "2       [CLS]\n",
       "3       [SEP]\n",
       "4      [MASK]\n",
       "..        ...\n",
       "295     ##c12\n",
       "296     ##[Si\n",
       "297  ##c(C(=O\n",
       "298   ##[nH+]\n",
       "299  ##(CC(=O\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_fwf('./vocab_bpe_300.txt', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit import Chem\n",
    "# from transformers import BertTokenizer\n",
    "\n",
    "# from typing import List\n",
    "# import re\n",
    "\n",
    "# ## REGEX_PATTERN ##\n",
    "# SMI_REGEX_PATTERN =  r\"(\\%\\([0-9]{3}\\)|\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\||\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
    "\n",
    "# class RegexTokenizer:\n",
    "#     \"\"\"Run regex tokenization\"\"\"\n",
    "\n",
    "#     def __init__(self, regex_pattern: str=SMI_REGEX_PATTERN) -> None:\n",
    "#         \"\"\"Constructs a RegexTokenizer.\n",
    "#         Args:\n",
    "#             regex_pattern: regex pattern used for tokenization.\n",
    "#             suffix: optional suffix for the tokens. Defaults to \"\".\n",
    "#         \"\"\"\n",
    "#         self.regex_pattern = regex_pattern\n",
    "#         self.regex = re.compile(self.regex_pattern)\n",
    "\n",
    "#     def tokenize(self, text: str) -> List[str]:\n",
    "#         \"\"\"Regex tokenization.\n",
    "#         Args:\n",
    "#             text: text to tokenize.\n",
    "#         Returns:\n",
    "#             extracted tokens separated by spaces.\n",
    "#         \"\"\"\n",
    "#         tokens = [token for token in self.regex.findall(text)]\n",
    "#         return tokens\n",
    "    \n",
    "    \n",
    "# class SMILESTokenizer(BertTokenizer):\n",
    "#     def __init__(self, \n",
    "#         vocab_file: str,\n",
    "#         unk_token: str = \"[UNK]\",\n",
    "#         sep_token: str = \"[SEP]\",\n",
    "#         pad_token: str = \"[PAD]\",\n",
    "#         cls_token: str = \"[CLS]\",\n",
    "#         mask_token: str = \"[MASK]\",\n",
    "#         do_lower_case = False,\n",
    "#         **kwargs,\n",
    "#         ) -> None:\n",
    "        \n",
    "#         super().__init__(\n",
    "#             vocab_file=vocab_file,\n",
    "#             unk_token=unk_token,\n",
    "#             sep_token=sep_token,\n",
    "#             pad_token=pad_token,\n",
    "#             cls_token=cls_token,\n",
    "#             mask_token=mask_token,\n",
    "#             do_lower_case=do_lower_case,\n",
    "#             **kwargs,\n",
    "#         )\n",
    "        \n",
    "#         self.tokenizer = RegexTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_config = {\n",
    "        'embed_dim': 256,#256\n",
    "        'property_width': 384, #???\n",
    "        'batch_size': 4,#64\n",
    "        'temp': 0.07,\n",
    "        'queue_size': 2048,#65536\n",
    "        'momentum': 0.995,\n",
    "        'alpha': 0.4,\n",
    "        'bert_config': './config_bert.json',    #config file for BERT model. The configuration for ViT can be manually changed in albef.py\n",
    "        'schedular': {'sched': 'cosine', 'lr': 1e-4, 'epochs': 30, 'min_lr': 1e-5,\n",
    "                      'decay_rate': 1, 'warmup_lr': 1e-5, 'warmup_epochs': 20, 'cooldown_epochs': 0},\n",
    "        'optimizer': {'opt': 'adamW', 'lr': 1e-4, 'weight_decay': 0.02}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMILES Sequence tokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn \n",
    "from xbert import BertConfig, BertForMaskedLM \n",
    "\n",
    "\n",
    "class SPMM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 tokenizer=None,\n",
    "                 config=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tokenizer = BertTokenizer('./vocab_bpe_300.txt', do_lower_case=False,do_basic_tokenize=False)\n",
    "        embed_dim = config['embed_dim']\n",
    "\n",
    "        smilesAndFusion_config = BertConfig.from_json_file('./config_bert_smiles_and_fusion_encoder.json')\n",
    "        property_config = BertConfig.from_json_file('./config_bert_property_encoder.json')\n",
    "        self.smilesEncoder = BertForMaskedLM(config = smilesAndFusion_config)\n",
    "        self.propertyEncoder = BertForMaskedLM(config = property_config)\n",
    "\n",
    "        smilesWidth = self.smilesEncoder.config.hidden_size\n",
    "        propertyWidth = config['property_width']\n",
    "\n",
    "        self.smilesProj = nn.Linear(smilesWidth, embed_dim)\n",
    "        self.propertyProj = nn.Linear(propertyWidth, embed_dim)\n",
    "\n",
    "        # special tokens & embedding for property input\n",
    "        self.propertyEmbed = nn.Linear(1, propertyWidth)\n",
    "        self.property_CLS = nn.Parameter(torch.zeros([1, 1, propertyWidth]))\n",
    "        self.property_MASK = nn.Parameter(torch.zeros([1, 1, propertyWidth]))\n",
    "        \n",
    "\n",
    "        self.temp = nn.Parameter(torch.ones([]) * config['temp'])\n",
    "        self.queue_size = config['queue_size']\n",
    "        self.momentum = config['momentum']\n",
    "        \n",
    "        self.itm_head_smiles = nn.Linear(smilesWidth, 2)\n",
    "        self.itm_head_properties = nn.Linear(propertyWidth, 2)\n",
    "\n",
    "        # Momentum Model\n",
    "\n",
    "        self.smilesEncoder_m = BertForMaskedLM(config = smilesAndFusion_config)\n",
    "        self.propertyEncoder_m = BertForMaskedLM(config = property_config)\n",
    "        self.smilesProj_m = nn.Linear(smilesWidth, embed_dim)\n",
    "        self.propertyProj_m = nn.Linear(propertyWidth, embed_dim)\n",
    "\n",
    "        self.model_pairs = [[self.smilesEncoder, self.smilesEncoder_m],\n",
    "                            [self.smilesProj, self.smilesProj_m],\n",
    "                            [self.propertyEncoder, self.propertyEncoder_m],\n",
    "                            [self.propertyProj, self.propertyProj_m]]\n",
    "        \n",
    "        self.copy_params()\n",
    "\n",
    "        # Create the queue\n",
    "        self.register_buffer(\"smiles_queue\", torch.randn(embed_dim, self.queue_size))\n",
    "        self.register_buffer(\"text_queue\", torch.randn(embed_dim, self.queue_size))\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "        self.property_queue = nn.functional.normalize(self.property_queue, dim=0)\n",
    "        self.smiles_queue = nn.functional.normalize(self.smiles_queue, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, property, smilesIds, smilesAttentionMask, alpha=0):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.temp.clamp_(0.001, 0.5)\n",
    "\n",
    "        #1. property tokenizing & embedding\n",
    "        embedProperty = self.propertyEmbed(property.unsqueeze(2))\n",
    "        \n",
    "        property_MASK = self.property_MASK.expand(property.size(0), property.size(1), -1)\n",
    "        halfMask = torch.bernoulli(torch.ones_like(property)*0.5)\n",
    "        halfMaskBatch = halfMask.unsqueeze(2).repeat(1,1,property_MASK.size(2))\n",
    "        maskedProperty = embedProperty* halfMaskBatch \n",
    "        inputProperty = torch.cat([self.property_CLS.expand(property.size(0), -1,-1), maskedProperty], dim=1)\n",
    "\n",
    "        #2. input through encoders\n",
    "        encProperty = self.propertyEncoder(inputs_embeds=inputProperty, return_dict=True).last_hidden_state\n",
    "        propertyAtts = torch.ones(encProperty.size()[:-1], dtype=torch.long).to(inputProperty.device)\n",
    "        propertyFeat = F.normalize(self.propertyProj(encProperty[:,0,:]), dim=-1)\n",
    "\n",
    "        encSmiles = self.smilesEncoder.bert(smilesIds, attention_mask=smilesAttentionMask, return_dict=True).last_hidden_State\n",
    "        smilesFeat = F.normalize(self.smilesProj(encSmiles[:,0,:]), dims=-1)\n",
    "        \n",
    "        #3. Contrastive Loss between the different & within the same modalities\n",
    "        with torch.no_grad():\n",
    "            self._momentum_update()\n",
    "            \n",
    "            encProperty_m = self.propertyEnoder_m(inputs_embeds=inputProperty, return_dic=True).last_hidden_state\n",
    "            propertyAtts_m = torch.ones(encProperty_m.size()[:-1], dtype=torch.long).to(inputProperty.device)\n",
    "            propertyFeat_m = F.normalize(self.propertyProj_m(encProperty_m[:,0,:]), dim=-1)\n",
    "            propertyFeatAll = torch.cat([propertyFeat_m.t(), self.property_queue.clone().detach()], dim=1)\n",
    "            \n",
    "            encSmiles_m = self.smilesEncoder_m.bert(smilesIds,attention_mask=smilesAttentionMask, return_dict=True).last_hidden_state\n",
    "            smilesFeat_m = F.normalize(self.smilesProj_m(encSmiles[:,0,:]), dim=-1)\n",
    "            smilesFeatAll = torch.cat([smilesFeat_m.t(), self.smiles_queue.clone().detach()], dim=1)\n",
    "\n",
    "            sim_p2s_m = propertyFeat_m @ smilesFeatAll / self.temp\n",
    "            sim_s2p_m = smilesFeat_m @ propertyFeatAll / self.temp\n",
    "            sim_p2p_m = propertyFeat_m @ propertyFeatAll / self.temp\n",
    "            sim_s2s_m = smilesFeat_m @ smilesFeatAll / self.temp\n",
    "\n",
    "            ## Make Target ##\n",
    "            sim_targets_diff = torch.zeros(sim_p2s_m.size()).to(property.device)\n",
    "            sim_targets_diff.fill_diagonal_(1)\n",
    "            sim_targets_same = torch.zeros(sim_p2p_m.size()).to(property.device)\n",
    "            sim_targets_same.fill_diagonal_(1)\n",
    "          \n",
    "            sim_p2s_targets = alpha * F.softmax(sim_p2s_m, dim=1) + (1-alpha) * sim_targets_diff\n",
    "            sim_s2p_targets = alpha * F.softmax(sim_s2p_m, dim=1) + (1-alpha) * sim_targets_diff\n",
    "            sim_p2p_targets = alpha * F.softmax(sim_p2p_m, dim=1) + (1-alpha) * sim_targets_same\n",
    "            sim_s2s_targets = alpha * F.softmax(sim_s2s_m, dim=1) + (1-alpha) * sim_targets_same\n",
    "\n",
    "        sim_p2s = propertyFeat @ smilesFeatAll / self.temp\n",
    "        sim_s2p = smilesFeat @ propertyFeatAll / self.temp\n",
    "        sim_p2p = propertyFeat @ propertyFeatAll / self.temp\n",
    "        sim_s2s = smilesFeat @ smilesFeatAll / self.temp \n",
    "\n",
    "        loss_p2s = -torch.sum(F.log_softmax(sim_p2s, dim=1)*sim_p2s_targets, dim=1).mean()\n",
    "        loss_s2p = -torch.sum(F.log_softmax(sim_s2p, dim=1)*sim_s2p_targets, dim=1).mean()\n",
    "        loss_p2p = -torch.sum(F.log_softmax(sim_p2p, dim=1)*sim_p2p_targets, dim=1).mean()\n",
    "        loss_s2s = -torch.sum(F.log_softmax(sim_p2p, dim=1)*sim_s2s_targets, dim=1).mean()\n",
    "\n",
    "        loss_psc = (loss_p2s + loss_s2p + loss_p2p + loss_s2s)/2 \n",
    "\n",
    "        self._dequeue_and_enqueue(propertyFeat_m, smilesFeat_m)\n",
    "\n",
    "        #4. X-attention\n",
    "        \n",
    "\n",
    "        #5. Next property prediction\n",
    "\n",
    "        #6. Next word prediction\n",
    "\n",
    "        #7. SMILES-property matching \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def copy_params(self):\n",
    "        for model_pair in self.model_pairs:\n",
    "            for param, param_m in zip(model_pair[0].parameters(), model_pair[1].parameters()):\n",
    "                param_m.data.copy_(param.data)  # initialize\n",
    "                param_m.requires_grad = False\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _momentum_update(self):\n",
    "        for model_pair in self.model_pairs:\n",
    "            for param, param_m in zip(model_pair[0].parameter(), model_pair[1].parameter()):\n",
    "                param_m.data = param_m.data * self.momentum + param.data * (1. - self.momentum)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, property_feat, smiles_feat):\n",
    "        property_feats = concat_all_gather(property_feat)\n",
    "        smiles_feats = concat_all_gather(smiles_feat)\n",
    "\n",
    "        batch_size = property_feats.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.queue_size % batch_size == 0\n",
    "\n",
    "        self.property_queue[:, ptr:ptr + batch_size] = property_feats.T\n",
    "        self.smiles_queue[:, ptr:ptr + batch_size] = smiles_feats.T\n",
    "        ptr = (ptr + batch_size) & self.queue_size \n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    tensors_gather = [torch.ones_like(tensor)\n",
    "        for _ in range(torch.distributed.get_world_size())]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   5, 146,   8, 212, 112, 115,  98, 222, 114,  98,   3]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "sample_SMILES = sample[0]\n",
    "sample_prop = sample[1]\n",
    "\n",
    "SMILES_token = tokenizer(sample_SMILES)\n",
    "input_ids = torch.LongTensor([SMILES_token['input_ids']])\n",
    "print(input_ids)\n",
    "attention_mask = torch.Tensor([SMILES_token['attention_mask']])\n",
    "print(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xbert import BertConfig, BertForMaskedLM\n",
    "\n",
    "smilesAndFusion_config = BertConfig.from_json_file('./config_bert_smiles_and_fusion_encoder.json')\n",
    "smilesEncoder = BertForMaskedLM(config = smilesAndFusion_config)\n",
    "\n",
    "property_config = BertConfig.from_json_file('./config_bert_property_encoder.json')\n",
    "propertyEncoder = BertForMaskedLM(config = property_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.9597,  1.2143, -0.5380,  ...,  1.0735, -0.7072,  0.1639],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "propertyOriginal = torch.rand([1,53])\n",
    "embedProperty = nn.Linear(1, 384)(propertyOriginal.unsqueeze(2))\n",
    "#print(embedProperty)\n",
    "\n",
    "property_CLS = nn.Parameter(torch.zeros([1,1,384]))\n",
    "property_MASK = nn.Parameter(torch.zeros([1,1,384]))\n",
    "property_MASK = property_MASK.expand(propertyOriginal.size(0), propertyOriginal.size(1), -1)\n",
    "\n",
    "halfMask = torch.bernoulli(torch.ones_like(propertyOriginal)*0.5)\n",
    "halfMaskBatch = halfMask.unsqueeze(2).repeat(1,1,property_MASK.size(2))\n",
    "maskedProperty = embedProperty*halfMaskBatch + property_MASK*halfMaskBatch\n",
    "\n",
    "print((embedProperty*halfMaskBatch))\n",
    "#print(property_MASK*(1-halfMaskBatch))\n",
    "\n",
    "inputProperty = torch.cat([property_CLS.expand(propertyOriginal.size(0), -1,-1), maskedProperty], dim=1)\n",
    "\n",
    "#print(inputProperty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 54, 384])\n",
      "torch.Size([1, 12, 384])\n"
     ]
    }
   ],
   "source": [
    "encodedProp = propertyEncoder.bert(inputs_embeds=inputProperty, return_dict=True).last_hidden_state\n",
    "print(encodedProp.shape)\n",
    "encodedSmiles = smilesEncoder.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=True, mode='text').last_hidden_state\n",
    "print(encodedSmiles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.8762e-02,  1.1928e-01, -7.7999e-01,  ...,  9.0458e-01,\n",
       "          1.5004e+00,  4.4767e-01],\n",
       "        [ 5.7109e-02,  1.2312e-01,  5.8970e-01,  ...,  6.8499e-01,\n",
       "          4.4771e-01, -1.0068e+00],\n",
       "        [-9.9284e-03, -1.1385e+00,  4.2117e-01,  ...,  1.9698e-01,\n",
       "          6.9416e-01,  1.2608e+00],\n",
       "        ...,\n",
       "        [ 4.4396e-02, -8.0955e-01,  4.6936e-01,  ..., -1.2962e-01,\n",
       "         -1.3693e+00, -8.3211e-02],\n",
       "        [-1.3305e-03, -1.5741e+00, -1.1515e+00,  ..., -1.0564e-02,\n",
       "         -2.6165e+00,  2.7643e-01],\n",
       "        [-3.4384e-02,  1.6921e+00,  6.9289e-01,  ...,  4.4668e-01,\n",
       "          6.8955e-01,  4.2221e-03]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "propertyProj = nn.Linear(384, 384)\n",
    "\n",
    "propertyAtts = torch.ones(encodedProp.size()[:-1], dtype=torch.long).to(inputProperty.device)\n",
    "propertyFeat = F.normalize(propertyProj(encodedProp[:,0,:]), dim=-1)\n",
    "\n",
    "property_queue = torch.randn(384, 2048)\n",
    "property_queue.clone().detach()\n",
    "\n",
    "propertyFeatAll = torch.cat([propertyFeat.t(), property_queue.clone().detach()], dim=1)\n",
    "propertyFeatAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.8762e-02,  1.1928e-01, -7.7999e-01,  ...,  9.0458e-01,\n",
       "          1.5004e+00,  4.4767e-01],\n",
       "        [ 5.7109e-02,  1.2312e-01,  5.8970e-01,  ...,  6.8499e-01,\n",
       "          4.4771e-01, -1.0068e+00],\n",
       "        [-9.9284e-03, -1.1385e+00,  4.2117e-01,  ...,  1.9698e-01,\n",
       "          6.9416e-01,  1.2608e+00],\n",
       "        ...,\n",
       "        [ 4.4396e-02, -8.0955e-01,  4.6936e-01,  ..., -1.2962e-01,\n",
       "         -1.3693e+00, -8.3211e-02],\n",
       "        [-1.3305e-03, -1.5741e+00, -1.1515e+00,  ..., -1.0564e-02,\n",
       "         -2.6165e+00,  2.7643e-01],\n",
       "        [-3.4384e-02,  1.6921e+00,  6.9289e-01,  ...,  4.4668e-01,\n",
       "          6.8955e-01,  4.2221e-03]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesProj = nn.Linear(384, 384)\n",
    "smilesFeat = F.normalize(smilesProj(encodedSmiles[:,0,:]), dim=-1)\n",
    "\n",
    "smiles_queue = torch.randn(384, 2048)\n",
    "smiles_queue.clone().detach()\n",
    "\n",
    "smilesFeatAll = torch.cat([smilesFeat.t(), smiles_queue.clone().detach()], dim=1)\n",
    "propertyFeatAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2049])\n",
      "torch.Size([1, 2049])\n"
     ]
    }
   ],
   "source": [
    "sim_p2s = (propertyFeat @ smilesFeatAll)\n",
    "sim_targets = torch.zeros(sim_p2s.size()).to(propertyOriginal.device)\n",
    "print(sim_targets.shape)\n",
    "\n",
    "sim_s2p = smilesFeat @ propertyFeatAll\n",
    "sim_targets_same = torch.zeros(sim_s2p.size()).to(propertyOriginal.device)\n",
    "print(sim_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputProperty_pos = smilesEncoder.bert(encoder_embeds = encodedProp,\n",
    "                               attention_mask = propertyAtts,\n",
    "                               encoder_hidden_states = encodedSmiles,\n",
    "                               encoder_attention_mask = attention_mask,\n",
    "                               return_dict = True,\n",
    "                               mode= 'fusion'\n",
    "                               ).last_hidden_state[:,0,:]\n",
    "outputSmiles_pos = smilesEncoder.bert(encoder_embeds = encodedSmiles,\n",
    "                             attention_mask = attention_mask,\n",
    "                             encoder_hidden_states = encodedProp,\n",
    "                             encoder_attention_mask = propertyAtts,\n",
    "                             return_dict = True,\n",
    "                             mode= 'fusion'\n",
    "                             ).last_hidden_state[:,0,:]\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384])\n",
      "torch.Size([1, 384])\n"
     ]
    }
   ],
   "source": [
    "print(outputProperty_pos.shape)\n",
    "print(outputSmiles_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "weights_p2s = F.softmax(sim_p2s[:,:batch_size], dim=1)\n",
    "weights_s2p = F.softmax(sim_s2p[:,:batch_size], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4548, -2.2780,  0.4974,  ...,  1.3426,  1.1778,  0.0176],\n",
       "         [ 0.7172, -1.7073,  1.8965,  ..., -0.5926,  0.4046, -1.1316],\n",
       "         [ 0.0257, -1.9203, -0.8604,  ...,  0.8587,  0.3136,  0.8495],\n",
       "         ...,\n",
       "         [ 1.1889,  2.1723,  0.2084,  ...,  1.6081, -0.2492,  0.3495],\n",
       "         [ 0.4636, -1.4379,  1.1198,  ..., -0.5428,  1.1467,  0.3389],\n",
       "         [-0.0511, -2.6801,  0.0794,  ...,  0.0811,  1.3672,  0.6650]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedProp_neg = []\n",
    "neg_idx = torch.multinomial(weights_p2s[0], 1).item()\n",
    "encodedProp_neg.append(encodedProp[neg_idx])\n",
    "encodedProp_neg = torch.stack(encodedProp_neg, dim=0)\n",
    "encodedProp_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7253, -1.3550, -0.2006,  ...,  1.6776,  2.6813,  0.3892],\n",
       "         [-0.7899, -0.0231, -0.4013,  ...,  0.6710,  0.1847,  0.5813],\n",
       "         [ 0.4161,  0.4358,  1.5455,  ...,  1.6195,  1.2633,  0.4084],\n",
       "         ...,\n",
       "         [ 1.0883, -1.5810, -1.8105,  ..., -0.3974, -0.1430,  1.8496],\n",
       "         [-0.0414, -0.7358,  0.3426,  ...,  1.5155,  0.0925,  1.8695],\n",
       "         [-0.3318,  0.1581, -0.8436,  ...,  2.0988,  0.1942,  0.6979]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedSmiles_neg = []\n",
    "smilesAtts_neg = []\n",
    "\n",
    "neg_idx = torch.multinomial(weights_s2p[0], 1).item()\n",
    "encodedSmiles_neg.append(encodedSmiles[neg_idx])\n",
    "smilesAtts_neg.append(attention_mask[neg_idx])\n",
    "encodedSmiles_neg = torch.stack(encodedSmiles_neg, dim=0)\n",
    "smilesAtts_neg = torch.stack(smilesAtts_neg, dim=0)\n",
    "\n",
    "encodedSmiles_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "encProperty_all = torch.cat([encodedProp, encodedProp_neg], dim=0)\n",
    "propertyAtts_all = torch.cat([propertyAtts, propertyAtts], dim=0)\n",
    "\n",
    "encSmiles_all = torch.cat([encodedSmiles_neg, encodedSmiles], dim=0)\n",
    "smilesAtts_all = torch.cat([smilesAtts_neg, attention_mask], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputProperty_neg = smilesEncoder.bert(encoder_embeds = encProperty_all,\n",
    "                                    attention_mask = propertyAtts_all,\n",
    "                                    encoder_hidden_states = encSmiles_all,\n",
    "                                    encoder_attention_mask = smilesAtts_all,\n",
    "                                    return_dict = True,\n",
    "                                    mode = 'fusion'\n",
    "                                    ).last_hidden_state[:,0,:]\n",
    "#outputProperty_neg = outputProperty_neg\n",
    "outputSmiles_neg = smilesEncoder.bert(encoder_embeds = encSmiles_all,\n",
    "                                    attention_mask = smilesAtts_all,\n",
    "                                    encoder_hidden_states = encProperty_all,\n",
    "                                    encoder_attention_mask = propertyAtts_all,\n",
    "                                    return_dict = True,\n",
    "                                    mode = 'fusion'\n",
    "                                    ).last_hidden_state[:,0,:]\n",
    "#outputSmiles_neg = outputSmiles_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0922,  0.4150],\n",
       "        [-0.0426,  0.4170],\n",
       "        [-0.0690,  0.5579]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeds = torch.cat([outputProperty_pos, outputSmiles_pos], dim=-1)\n",
    "neg_embeds = torch.cat([outputProperty_neg, outputSmiles_neg], dim=-1)\n",
    "\n",
    "ps_embeddings = torch.cat([pos_embeds, neg_embeds], dim=0)\n",
    "ps_embeddings.shape\n",
    "ps_output = nn.Linear(768, 2)(ps_embeddings)\n",
    "ps_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psm_labels = torch.cat([torch.ones(1, dtype=torch.long), torch.zeros(2, dtype=torch.long)], dim=0).to(propertyOriginal.device)\n",
    "psm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8251, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_psm = F.cross_entropy(ps_output, psm_labels)\n",
    "loss_psm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "         False,  True]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bernoulli(torch.full(input_ids.shape, 0.8)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 300])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_m  = smilesEncoder(input_ids,\n",
    "                          attention_mask = attention_mask,\n",
    "                          encoder_hidden_states = encodedProp,\n",
    "                          encoder_attention_mask = propertyAtts,\n",
    "                          return_dict = True,\n",
    "                          is_decoder = True,\n",
    "                          return_logits = True \n",
    "                          )\n",
    "\n",
    "logits_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6876,  0.3855, -0.7382,  ..., -0.7377,  0.0895, -0.0314],\n",
       "         [-0.2983, -0.5888,  0.1915,  ..., -0.3460, -0.1436,  0.1975],\n",
       "         [ 0.0608,  0.7610, -0.1273,  ...,  0.4475,  0.3133, -0.2379],\n",
       "         ...,\n",
       "         [ 0.2022,  0.0816, -0.3696,  ..., -0.6651, -0.0205, -0.0895],\n",
       "         [-0.0936,  0.1425, -0.1666,  ...,  0.2432, -0.2964,  0.4195],\n",
       "         [-0.2694,  0.2435,  0.0043,  ...,  0.0089,  0.3970,  0.3363]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = input_ids.clone()[:,1:]\n",
    "logits_m.permute((0,2,1), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m inputs_ids \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mclone()\n\u001b[1;32m----> 2\u001b[0m labels \u001b[39m=\u001b[39m inputs_ids\u001b[39m.\u001b[39;49mclone()[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,:]\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "inputs_ids = input_ids.clone()\n",
    "labels = inputs_ids.clone()[:,:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [SEP]\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BISPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01a600ee4c343e99426c2b6e5bbd26d22d733d8f4b38429737b3f68048676463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
